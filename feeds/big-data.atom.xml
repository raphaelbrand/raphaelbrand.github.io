<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Raphael Brand | Blog</title><link href="https://raphaelbrand.github.io/" rel="alternate"></link><link href="https://raphaelbrand.github.io/feeds/big-data.atom.xml" rel="self"></link><id>https://raphaelbrand.github.io/</id><updated>2016-10-23T20:23:00+02:00</updated><entry><title>Run hadoop streaming jobs with pypy on EMR</title><link href="https://raphaelbrand.github.io/run-hadoop-streaming-jobs-with-pypy-on-emr.html" rel="alternate"></link><published>2016-10-23T20:23:00+02:00</published><updated>2016-10-23T20:23:00+02:00</updated><author><name>Raphael Brand</name></author><id>tag:raphaelbrand.github.io,2016-10-23:run-hadoop-streaming-jobs-with-pypy-on-emr.html</id><summary type="html">&lt;p&gt;While python is very nice language, it tends to be a lot slower for CPU bound tasks than compiled languages or languages with a &lt;a href="https://en.wikipedia.org/wiki/Just-in-time_compilation"&gt;JIT&lt;/a&gt; compiler &lt;a href="http://benchmarksgame.alioth.debian.org/"&gt;[1]&lt;/a&gt;. While most people just use the standard CPython implementation, there are also alternatives out there. One of them being &lt;a href="http://pypy.org"&gt;pypy&lt;/a&gt;, which has a JIT compiler. The great thing about this is, that for some cases you get some big speedups without changing any thing in your code! Let's try it out with a simple example. We are going to load a file with 5 million lines where each line is a json object. The code looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;fileinput&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;fileinput&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And the results are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPython: 50s&lt;/li&gt;
&lt;li&gt;pypy: 9s&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Yes you could also use a library like &lt;a href="https://pypi.python.org/pypi/ujson"&gt;ujson&lt;/a&gt; to speed up json parsing, but this example is only to demonstrate how your code can run faster without having to change anything. But be aware that not all libraries are compatible with pypy. For more information read &lt;a href="http://pypy.org/compat.html"&gt;here&lt;/a&gt;. Also pypy usually uses more memory than CPython.&lt;/p&gt;
&lt;h2&gt;Installing pypy on EMR&lt;/h2&gt;
&lt;p&gt;The easiest way to get pypy running on the EMR AMIs is to use the binaries by &lt;a href="https://github.com/squeaky-pl/portable-pypy"&gt;squeaky-pl&lt;/a&gt;. Since all your machines in the cluster have to pull this binary, it is best to put it in a s3 bucket first. Also put this &lt;a href="https://bootstrap.pypa.io/get-pip.py"&gt;file&lt;/a&gt; in the bucket. Then add this to your bootstrap:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;aws s3 cp s3://YOUR-BUCKET/pypy-5.4.1-linux_x86_64-portable.tar.bz2 .
mv pypy-5.4.1-linux_x86_64-portable.tar.bz2 /home/hadoop/
&lt;span class="nb"&gt;cd&lt;/span&gt; /home/hadoop/
tar -xjf pypy-5.4.1-linux_x86_64-portable.tar.bz2
sudo ln -sf /home/hadoop/pypy-5.4.1-linux_x86_64-portable.tar.bz2/bin/pypy /usr/bin/pypy
aws s3 cp s3://YOUR-BUCKET/get-pip.py .
pypy get-pip.py
sudo ln -sf /home/hadoop/pypy-5.4.1-linux_x86_64-portable.tar.bz2/bin/pypy /usr/bin/pip /usr/bin/pypy-pip
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you need to install more libraries use &lt;strong&gt;pypy-pip&lt;/strong&gt; instead of the normal &lt;strong&gt;pip&lt;/strong&gt;. This bootstrap also makes sure that the preinstalled python environment is left untouched as it can lead to problems if you do overwrite it.&lt;/p&gt;
&lt;h2&gt;Running hadoop jobs with pypy&lt;/h2&gt;
&lt;p&gt;If you bootstrapped your cluster correctly you should now be able to run hadoop streaming jobs with pypy. Refer to this &lt;a href="http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/CLI_CreateStreaming.html"&gt;link&lt;/a&gt; on how to run a streaming step on emr. Obviously choose pypy instead of python2.7 for mapper and reducer excutable.&lt;/p&gt;
&lt;h2&gt;Run hadoop jobs with mrjob and pypy&lt;/h2&gt;
&lt;p&gt;Since i run most of my jobs with &lt;a href="http://pythonhosted.org/mrjob/"&gt;mrjob&lt;/a&gt; i needed to figure out on how to change the python binary. You can do so by specifing the &lt;a href="https://pythonhosted.org/mrjob/guides/configs-all-runners.html#option-python_bin"&gt;python_bin&lt;/a&gt; configuration.&lt;/p&gt;</summary><category term="hadoop emr streaming python"></category></entry></feed>